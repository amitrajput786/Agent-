{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitrajput786/Agent-/blob/main/weave/cookbooks/source/Intro_to_Weave_Hello_Trace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZmKBnUE8bGR"
      },
      "source": [
        "# Introduction to Traces\n",
        "\n",
        "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "Weave is a toolkit for developing AI-powered applications.\n",
        "\n",
        "Use Weave traces to capture the inputs, outputs, and internal structure of your Python function automatically to observe and debug LLM applications.\n",
        "\n",
        "When you decorate a function with `@weave.op`, Weave records a rich trace of the function while it runs, including any nested operations or external API calls. Use the trace to to debug, understand, and visualize interactions between your code and LLM models, without leaving your notebook.\n",
        "\n",
        "To get started, complete the prerequisites. Then, define a function decorated with `@weave.op` decorator and run it on an example input to track LLM calls. Weave captures and visualizes the trace automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jxECTbwy8cvT",
        "outputId": "d0f388ef-3d0b-4a94-9990-d0626997211b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/813.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m813.3/813.3 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/89.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Ensure your dependencies are installed with:\n",
        "!pip install --quiet jedi openai weave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ujOegcPY8j7z",
        "outputId": "e95ab35f-5067-4c28-c198-5887dab254c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set up your W&B project (team name/project name): sticker_creator\n",
            "Set up your W&B API key (Create an API key at https://wandb.ai/settings): 路路路路路路路路路路\n",
            "Enter your OpenAI API Key (Find it at https://platform.openai.com/api-keys): 路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "#@title Set up your credentials\n",
        "inference_provider = \"OpenAI\" #@param [\"W&B Inference\", \"OpenAI\"]\n",
        "\n",
        "# Set up your W&B project and credentials\n",
        "os.environ[\"WANDB_ENTITY_PROJECT\"] = input(\"Set up your W&B project (team name/project name): \")\n",
        "os.environ[\"WANDB_API_KEY\"] = getpass.getpass(\"Set up your W&B API key (Create an API key at https://wandb.ai/settings): \")\n",
        "\n",
        "# Set up your OpenAI API key\n",
        "if inference_provider == \"OpenAI\":\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key (Find it at https://platform.openai.com/api-keys): \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pTUHuulv8afx",
        "outputId": "65328c1d-0c35-465a-e37f-535c88b3ba27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m\u001b[1mweave\u001b[0m: wandb version 0.24.0 is available!  To upgrade, please run:\n",
            "\u001b[36m\u001b[1mweave\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: amitrajput51169.\n",
            "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/amitrajput51169-nit-rourkela/sticker_creator/weave\n",
            "\u001b[36m\u001b[1mweave\u001b[0m:  https://wandb.ai/amitrajput51169-nit-rourkela/sticker_creator/r/call/019bc531-0317-7cb5-82f2-ddd0208e3b66\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sure! Here's a joke for you:\\n\\nWhy don't skeletons fight each other?\\n\\nBecause they don't have the guts!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import weave\n",
        "\n",
        "weave.init(os.environ[\"WANDB_ENTITY_PROJECT\"])\n",
        "\n",
        "@weave.op  # Decorator to track requests\n",
        "def create_completion(message: str) -> str:\n",
        "    if inference_provider == \"W&B Inference\":\n",
        "      client = OpenAI(\n",
        "          base_url=\"https://api.inference.wandb.ai/v1\",\n",
        "          api_key=os.environ[\"WANDB_API_KEY\"],\n",
        "          project=os.environ[\"WANDB_ENTITY_PROJECT\"],\n",
        "      )\n",
        "      model_name: str = \"OpenPipe/Qwen3-14B-Instruct\"\n",
        "    if inference_provider == \"OpenAI\":\n",
        "      client = OpenAI()\n",
        "      model_name: str = \"gpt-4.1-nano\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": message},\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "message = \"Tell me a joke.\"\n",
        "create_completion(message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rYInJm1bXNL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}